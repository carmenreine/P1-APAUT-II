{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e122345c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; border-radius:8px; padding:12px; text-align:center;\">\n",
    "\n",
    "# **PRACTICA 1: KNN y selección de atributos**\n",
    "\n",
    "</div>\n",
    "\n",
    "*Aprendizaje Automático*\n",
    "\n",
    "---\n",
    "\n",
    "**Grupo:** G-7312  \n",
    "**Número de pareja:** 01  \n",
    "**Miembros:**  \n",
    "- Leire Bernárdez Vázquez  \n",
    "- Carmen Reiné Rueda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8469e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15194f6d",
   "metadata": {},
   "source": [
    "### **1. Implementación de kNN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd33b30",
   "metadata": {},
   "source": [
    "***a) Descargue de los datos sobre cáncer de mama***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095517a3",
   "metadata": {},
   "source": [
    "***b) Preprocese el dataset siguiendo estos pasos:***\n",
    "\n",
    "***1. Separe los atributos de las etiquetas***\n",
    "\n",
    "***2. Divida los datos en una partici ́on con el 70 % de los puntos para training y el 30 % de los puntos para test***\n",
    "\n",
    "***3. Normalice los datos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298da668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data      # atributos\n",
    "y = data.target    # etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ac313",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0955a",
   "metadata": {},
   "source": [
    "***c) Si hubiera datos ausentes (missing values) y  ́estos se completaran:***\n",
    "\n",
    "\n",
    "***1. ¿Cómo cree que influiría el orden en el que se realizan las operaciones de normalizar y completar?***\n",
    "\n",
    "***2. ¿Qué pasaría si primero se completan los datos ausentes y luego se normaliza?***\n",
    "\n",
    "***3. ¿Y si primero se normaliza y luego se realiza la partición training-test?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9bb28",
   "metadata": {},
   "source": [
    "Respuesta:\n",
    "\n",
    "1. Primero completar y luego normalizar sería lo correcto. Primero imputamos valores faltantes (media, mediana, etc.), y después normalizamos, así la media/desviación se calcula sobre datos coherentes.\n",
    "2. Primero normalizar y luego completar no sería correcto. Los valores “NaN” distorsionarían la media/desviación, y la normalización no tendría sentido.\n",
    "3. Normalizar antes de dividir en train/test sería incorrecto. La media y desviación estarían influenciadas por el test set (data leakage). Siempre normalizamos después de dividir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3fc88",
   "metadata": {},
   "source": [
    "***d) A continuación, complete la clase KNNClassifier, cuyos atributos son el número de vecinos y una funci ́on distancia (una función cuyas entradas son dos vectores de la misma dimensión, y cuya salida es un numero real positivo). Complete el constructor y los m ́etodos fit y predict.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbf308",
   "metadata": {},
   "source": [
    "    Hecho, resivar el test y añadir cosas para ver si es óptimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5de154",
   "metadata": {},
   "source": [
    "***e) Utilice la clase anterior para predecir las etiquetas de los datos de test, con un número de vecinos k, fijo pero arbitrario.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNClassifier(k=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88f00e",
   "metadata": {},
   "source": [
    "    Aquí hay que usar random????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ea751",
   "metadata": {},
   "source": [
    "***f) Responda a la siguiente pregunta: ¿Qué ocurrir ́ıa si hubiera un desbalanceo de clases en el conjunto de entrenamiento? Si esto supone un problema, ¿podría proporcionar una solución?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2cdb49",
   "metadata": {},
   "source": [
    "Si una clase tiene muchos más ejemplos, KNN tenderá a predecir siempre esa clase.\n",
    "Soluciones posibles:\n",
    "- Ponderar los vecinos por la inversa de la distancia.\n",
    "- Usar técnicas de balanceo (oversampling/undersampling, SMOTE).\n",
    "- Elegir una métrica de evaluación robusta al desbalance (f1-score, balanced accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8eb5fc",
   "metadata": {},
   "source": [
    "***g) Responda a la siguiente pregunta: ¿Cuál es el coste en memoria del algoritmo KNN? ¿Se le ocurre alguna forma de reducirlo?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbf379",
   "metadata": {},
   "source": [
    "KNN es un algoritmo no paramétrico: guarda todos los datos de entrenamiento en memoria, que implica un coste O(Nxd).\n",
    "Para reducirlo:\n",
    "\n",
    "- Usar estructuras de búsqueda (KD-trees, ball trees).\n",
    "- Usar reducción de dimensionalidad (PCA, selección de atributos).\n",
    "- Usar un subconjunto representativo de datos (prototyping)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f7b09",
   "metadata": {},
   "source": [
    "***h) Utilice la funci ́on KNeighborsClassifier de la biblioteca de sklearn y, para el mismo n ́umero de vecinos k prediga las etiquetas del conjunto de test ypredsk. Si ypredcustom son las prediciones de su modelo, ¿cuál es el error medio entre las predicciones ypredsk e ypredcustom? ¿Por qué?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02031752",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sk_knn.fit(X_train, y_train)\n",
    "y_pred_sk = sk_knn.predict(X_test)\n",
    "\n",
    "# Error medio entre predicciones\n",
    "error = (y_pred_sk != y_pred).mean()\n",
    "print(\"Error medio:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90840b",
   "metadata": {},
   "source": [
    "    Hay que ver si da bien el error y justificar el porqué"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c200de",
   "metadata": {},
   "source": [
    "***e) Se encuentra usted a un individuo que afirma que, en vez de utilizar KNN, el prefiere usar la siguiente alternativa. Para predecir la etiqueta del punto x, toma los tres puntos más cercanos a x en el conjunto de training.***\n",
    "\n",
    "***Si las distancias de estos tres puntos al punto x son d1, d2 y d3, y sus respectivas etiquetas son y1, y2 e y3, la predicción vendrá dada por:***\n",
    "\n",
    "***f (x) = sign ( 3∑ i=1 (yi/di) )***\n",
    "\n",
    "***¿Considera que este método es mejor que KNN con k = 3? ¿Por qué?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4222d",
   "metadata": {},
   "source": [
    "Dado el modelo propuesto:\n",
    "\n",
    "- **KNN con k=3 estándar**: vota por mayoría simple. Todos los vecinos cuentan igual, aunque uno esté muy cerca y otro bastante más lejos.\n",
    "- **Método propuesto**: da más importancia a los vecinos más cercanos. Si un vecino está mucho más cerca que los otros dos, su etiqueta tiene más peso en la decisión.\n",
    "\n",
    "Teniendo en ceuenta el modelo descrito, podemos sacar las siguientes ventajas y desventajas:\n",
    "\n",
    "- **Ventaja**: puede ser más robusto en situaciones donde los vecinos están a distancias muy diferentes. Ejemplo: si tienes un vecino muy cercano de clase A y dos vecinos algo más lejanos de clase B, el método ponderado asignará A, mientras que KNN (k=3) daría B.\n",
    "- **Inconveniente**: si las distancias son muy similares, el método propuesto se comporta casi igual que KNN, pero es más sensible a la escala de las distancias (si no se normalizan bien los atributos, el peso puede distorsionarse).\n",
    "\n",
    "En conclusión, el método ponderado por distancias suele considerarse una mejora sobre KNN clásico porque aprovecha la información de cuán cerca está cada vecino, no solo cuántos hay. Sin embargo, no siempre será mejor en la práctica, depende de cómo estén distribuidos los datos y de la escala de los atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba994d2",
   "metadata": {},
   "source": [
    "### **2. Optimización de kNN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0c7ee",
   "metadata": {},
   "source": [
    "***a) Encuentre, utilizando validación cruzada, el número de vecinos óptimos, kopt.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe45300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador base\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Valores de k a probar\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}\n",
    "\n",
    "# Validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=cv, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "k_opt = grid.best_params_['n_neighbors']\n",
    "print(\"k óptimo:\", k_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ee1a7",
   "metadata": {},
   "source": [
    "    Revisar antes de preguntar si lo de param_grid sirve para usarse aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc8d60",
   "metadata": {},
   "source": [
    "***b) Dé la métrica de accuracy sobre el conjunto de test del clasificador KNN usando el valor kopt obtenido.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsClassifier(n_neighbors=k_opt)\n",
    "best_knn.fit(X_train, y_train)\n",
    "test_acc = best_knn.score(X_test, y_test)\n",
    "print(\"Accuracy en test:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08a285",
   "metadata": {},
   "source": [
    "    Para que vaya este primero hay que revisar que el a esté bien (aún así funciona)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5463e0",
   "metadata": {},
   "source": [
    "***c) ¿Cree que el valor kopt encontrado es el que proporciona mejor accuracy en el conjunto de test?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ea245",
   "metadata": {},
   "source": [
    "No necesariamente, ya que se elige para maximizar el rendimiento en validación cruzada, no en el test. Puede pasar que otro k dé un poco más de accuracy en el test, pero eso sería un sobreajuste al test si lo eligiéramos así. Lo correcto es quedarse con kopt por validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf720e",
   "metadata": {},
   "source": [
    "***d) Muestre en una gráfica el accuracy frente al n ́umero de vecinos, tanto para el conjunto de training como para el de test.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(1, 31)\n",
    "acc_train, acc_test = [], []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc_train.append(knn.score(X_train, y_train))\n",
    "    acc_test.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.plot(k_values, acc_train, label=\"Train\")\n",
    "plt.plot(k_values, acc_test, label=\"Test\")\n",
    "plt.xlabel(\"Número de vecinos (k)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs k en KNN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b1b9e",
   "metadata": {},
   "source": [
    "La gráfica muestra overfitting para k pequeños y underfitting para k muy grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654effad",
   "metadata": {},
   "source": [
    "***e) Repita los experimentos anteriores utilizando la distancia de Minkowski para p ∈ {1, 2, 10}.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7670ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [1, 2, 10]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_opt, p=p)  # p=1 (Manhattan), p=2 (Euclídea), p=10 (altamente no lineal)\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc = knn.score(X_test, y_test)\n",
    "    print(f\"Accuracy con Minkowski p={p}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf1297",
   "metadata": {},
   "source": [
    "    No sé si va bien, no me ejecutaba antes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ac887",
   "metadata": {},
   "source": [
    "***f) ¿Cómo afecta el valor de p a los resultados? ¿Qué p cree que es mejor?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed16d51",
   "metadata": {},
   "source": [
    "Dados los resultados:\n",
    "\n",
    "- p=1 (Manhattan): más robusto a outliers y diferencias grandes en un atributo.\n",
    "- p=2 (Euclídea): la más usada; capta bien la noción de distancia “geométrica”.\n",
    "- p=10: las mayores diferencias en una coordenada dominan la distancia → puede degradar rendimiento.\n",
    "\n",
    "Normalmente p=2 (euclídea) es la mejor opción, aunque depende del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f81cfc",
   "metadata": {},
   "source": [
    "    Revisar esta respuesta, sacada de teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54173d1a",
   "metadata": {},
   "source": [
    "### **3. Selección de atributos. A continuaci ́on procederemos a la reducci ́on de la dimensión de los datos.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740bcfa",
   "metadata": {},
   "source": [
    "***a) Usando el método VarianceThreshold de sklearn.feature selection para cierto umbral fijo u, elimine los atributos que no superen dicho umbral***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc928afb",
   "metadata": {},
   "source": [
    "***b) Analice cómo afecta la selección de atributos al accuracy del modelo. Para ello, fijado un valor de k para KNN, calcule accuracy en test. El conjunto de entrenamiento tendr ́a los atributos seleccionados para un umbral u ∈ [0, 1] concreto. El resultado será una gráfica con el accuracy frente al umbral u***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256cdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5da3c26",
   "metadata": {},
   "source": [
    "***c) ¿Tienen sentido los casos u = 0 y u = 1?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95906e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20f88b85",
   "metadata": {},
   "source": [
    "***d ) Ahora seleccione los mejores atributos del conjunto de datos utilizando SelectKBest de la librer ́ıa scikit-learn. Siga los siguientes pasos:***\n",
    "\n",
    "***1. Importe el método SelectKBest***\n",
    "\n",
    "***2. Utilice una estadística univariada como f_classif para la selección de atributos***\n",
    "\n",
    "***3. Seleccione los mejores K atributos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166bbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=K)\n",
    "selector.fit(X, y)\n",
    "X_selected = selector.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac0b06",
   "metadata": {},
   "source": [
    "***e) Combinando el método de selección de atributos con el clasificador KNN para un valor de k fijo, determinte cuál es el mejor valor de K. Nótese que k hace referencia al número de vecinos en KNN y K es el número de atributos seleccionado***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8f3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa0bdd25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "827c71cd",
   "metadata": {},
   "source": [
    "***f ) A continuación implemente el método de selección de atributos mRMR. Para ello, complete el archivo mRMR.py.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb97844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ee50f8",
   "metadata": {},
   "source": [
    "***g ) ¿Cuál es su mejor valor de k?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c298f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e59b26",
   "metadata": {},
   "source": [
    "***h) ¿Cul es el papel de la información mutua en el método mRMR? ¿Se podría sustituir por otra métrica?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ff363",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1829ca",
   "metadata": {},
   "source": [
    "***i ) ¿Qué método de selección de atributos, de los dos utilizados, considera que es mejor?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a710a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
